#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
R2 ì¦ë¶„ ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸

dist/ ë””ë ‰í† ë¦¬ì˜ íŒŒì¼ë“¤ì„ Cloudflare R2ì— ì—…ë¡œë“œ
ë³€ê²½ëœ íŒŒì¼ë§Œ ì—…ë¡œë“œ (íŒŒì¼ í•´ì‹œ ê¸°ë°˜)

í™˜ê²½ë³€ìˆ˜ í•„ìš”:
    export R2_ACCOUNT_ID="your_account_id"
    export R2_BUCKET_NAME="your_bucket_name"
    export R2_ACCESS_KEY_ID="your_access_key"
    export R2_SECRET_ACCESS_KEY="your_secret_key"

ì‚¬ìš©ë²•:
    python3 upload_to_r2.py              # ì¦ë¶„ ì—…ë¡œë“œ
    python3 upload_to_r2.py --dry-run    # ì‹œë®¬ë ˆì´ì…˜ (ì—…ë¡œë“œ ì•ˆ í•¨)
    python3 upload_to_r2.py --force      # ê°•ì œ ì „ì²´ ì—…ë¡œë“œ
"""

import argparse
import hashlib
import json
import os
import sys
import boto3
from pathlib import Path
from botocore.exceptions import ClientError

# R2 ì„¤ì • (í™˜ê²½ë³€ìˆ˜ì—ì„œ ì½ê¸°)
ACCOUNT_ID = os.getenv('R2_ACCOUNT_ID')
BUCKET_NAME = os.getenv('R2_BUCKET_NAME')

if not ACCOUNT_ID or not BUCKET_NAME:
    print("âŒ R2 ì„¤ì •ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("\në‹¤ìŒ í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”:")
    print("  export R2_ACCOUNT_ID='your_account_id'")
    print("  export R2_BUCKET_NAME='your_bucket_name'")
    print("  export R2_ACCESS_KEY_ID='your_access_key'")
    print("  export R2_SECRET_ACCESS_KEY='your_secret_key'")
    sys.exit(1)

ENDPOINT_URL = f"https://{ACCOUNT_ID}.r2.cloudflarestorage.com"

# ê²½ë¡œ ì„¤ì •
BASE_DIR = Path(__file__).parent.parent
DIST_DIR = BASE_DIR / "dist"
UPLOAD_CACHE_FILE = BASE_DIR / ".upload_cache.json"


def compute_file_hash(filepath: Path) -> str:
    """íŒŒì¼ì˜ SHA256 í•´ì‹œ ê³„ì‚°"""
    sha256 = hashlib.sha256()
    with open(filepath, 'rb') as f:
        for chunk in iter(lambda: f.read(4096), b""):
            sha256.update(chunk)
    return sha256.hexdigest()


def load_upload_cache() -> dict:
    """ì—…ë¡œë“œ ìºì‹œ ë¡œë“œ"""
    if UPLOAD_CACHE_FILE.exists():
        with open(UPLOAD_CACHE_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}


def save_upload_cache(cache: dict):
    """ì—…ë¡œë“œ ìºì‹œ ì €ì¥"""
    with open(UPLOAD_CACHE_FILE, 'w', encoding='utf-8') as f:
        json.dump(cache, f, indent=2)


def get_r2_client():
    """R2 í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
    access_key = os.getenv('R2_ACCESS_KEY_ID')
    secret_key = os.getenv('R2_SECRET_ACCESS_KEY')

    if not access_key or not secret_key:
        print("âŒ R2 í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("\në‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì •í•˜ì„¸ìš”:")
        print("  export R2_ACCESS_KEY_ID='your_access_key'")
        print("  export R2_SECRET_ACCESS_KEY='your_secret_key'")
        return None

    try:
        client = boto3.client(
            's3',
            endpoint_url=ENDPOINT_URL,
            aws_access_key_id=access_key,
            aws_secret_access_key=secret_key,
            region_name='auto'
        )
        return client
    except Exception as e:
        print(f"âŒ R2 í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return None


def get_content_type(filepath: Path) -> str:
    """íŒŒì¼ í™•ì¥ìì— ë”°ë¥¸ Content-Type ë°˜í™˜"""
    ext = filepath.suffix.lower()
    content_types = {
        '.json': 'application/json',
        '.svg': 'image/svg+xml',
        '.html': 'text/html',
        '.css': 'text/css',
        '.js': 'application/javascript',
    }
    return content_types.get(ext, 'application/octet-stream')


def upload_file(client, local_path: Path, r2_key: str, dry_run: bool = False) -> bool:
    """ë‹¨ì¼ íŒŒì¼ R2 ì—…ë¡œë“œ"""
    if dry_run:
        print(f"  [DRY-RUN] {r2_key}")
        return True

    try:
        content_type = get_content_type(local_path)

        with open(local_path, 'rb') as f:
            client.put_object(
                Bucket=BUCKET_NAME,
                Key=r2_key,
                Body=f,
                ContentType=content_type,
                CacheControl='public, max-age=3600'  # 1ì‹œê°„ ìºì‹œ
            )

        size_kb = local_path.stat().st_size / 1024
        print(f"  âœ… {r2_key} ({size_kb:.1f} KB)")
        return True

    except ClientError as e:
        print(f"  âŒ {r2_key}: {e}")
        return False


def collect_files_to_upload(force: bool = False) -> list:
    """ì—…ë¡œë“œí•  íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘ (ì¦ë¶„)"""
    if not DIST_DIR.exists():
        print(f"âŒ dist/ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {DIST_DIR}")
        print("   ë¨¼ì € build_incremental.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return []

    cache = {} if force else load_upload_cache()
    files_to_upload = []

    # dist/ í•˜ìœ„ ëª¨ë“  íŒŒì¼ ìŠ¤ìº”
    for filepath in DIST_DIR.rglob('*'):
        if not filepath.is_file():
            continue

        # R2 í‚¤ ìƒì„± (dist/ ì´í›„ ê²½ë¡œ)
        r2_key = str(filepath.relative_to(DIST_DIR))

        # íŒŒì¼ í•´ì‹œ ê³„ì‚°
        file_hash = compute_file_hash(filepath)

        # ìºì‹œ í™•ì¸
        cache_key = r2_key
        if not force and cache.get(cache_key) == file_hash:
            continue  # ë³€ê²½ ì—†ìŒ, ìŠ¤í‚µ

        files_to_upload.append({
            'local_path': filepath,
            'r2_key': r2_key,
            'hash': file_hash,
            'size': filepath.stat().st_size
        })

    return files_to_upload


def upload_all(dry_run: bool = False, force: bool = False):
    """ì „ì²´ ì—…ë¡œë“œ í”„ë¡œì„¸ìŠ¤"""
    print("=" * 70)
    print("R2 ì¦ë¶„ ì—…ë¡œë“œ")
    print("=" * 70)
    print(f"Account ID: {ACCOUNT_ID}")
    print(f"Bucket: {BUCKET_NAME}")
    print(f"ëª¨ë“œ: {'ì‹œë®¬ë ˆì´ì…˜' if dry_run else 'ì—…ë¡œë“œ'}")
    print(f"ê°•ì œ: {'ì˜ˆ' if force else 'ì•„ë‹ˆì˜¤'}")
    print("=" * 70)

    # R2 í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    client = get_r2_client()
    if not client and not dry_run:
        return

    # ì—…ë¡œë“œí•  íŒŒì¼ ìˆ˜ì§‘
    print(f"\nğŸ“ íŒŒì¼ ìŠ¤ìº” ì¤‘...")
    files_to_upload = collect_files_to_upload(force=force)

    if not files_to_upload:
        print("âœ… ì—…ë¡œë“œí•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤ (ëª¨ë“  íŒŒì¼ì´ ìµœì‹  ìƒíƒœ)")
        return

    # íŒŒì¼ í¬ê¸° í•©ê³„
    total_size = sum(f['size'] for f in files_to_upload) / 1024 / 1024
    print(f"ğŸ“Š ì—…ë¡œë“œ ëŒ€ìƒ: {len(files_to_upload)}ê°œ íŒŒì¼ ({total_size:.2f} MB)")

    # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜
    by_type = {}
    for f in files_to_upload:
        ext = Path(f['r2_key']).suffix
        by_type.setdefault(ext, []).append(f)

    print("\níŒŒì¼ ìœ í˜•ë³„:")
    for ext, items in sorted(by_type.items()):
        count = len(items)
        size_mb = sum(i['size'] for i in items) / 1024 / 1024
        print(f"  {ext or '(ì—†ìŒ)'}: {count}ê°œ ({size_mb:.2f} MB)")

    # ì—…ë¡œë“œ ì‹¤í–‰
    print(f"\n{'=' * 70}")
    print("ì—…ë¡œë“œ ì‹œì‘...")
    print("=" * 70)

    cache = load_upload_cache()
    success_count = 0
    fail_count = 0

    for file_info in files_to_upload:
        local_path = file_info['local_path']
        r2_key = file_info['r2_key']
        file_hash = file_info['hash']

        if upload_file(client, local_path, r2_key, dry_run=dry_run):
            success_count += 1
            if not dry_run:
                cache[r2_key] = file_hash
        else:
            fail_count += 1

    # ìºì‹œ ì €ì¥
    if not dry_run:
        save_upload_cache(cache)

    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 70)
    if dry_run:
        print(f"âœ… ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ!")
        print(f"  ì—…ë¡œë“œ ì˜ˆì •: {success_count}ê°œ")
    else:
        print(f"âœ… ì—…ë¡œë“œ ì™„ë£Œ!")
        print(f"  ì„±ê³µ: {success_count}ê°œ")
        print(f"  ì‹¤íŒ¨: {fail_count}ê°œ")
        print(f"\nR2 ë²„í‚·: https://pub-{ACCOUNT_ID}.r2.dev/")
    print("=" * 70)


def main():
    parser = argparse.ArgumentParser(
        description='R2 ì¦ë¶„ ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    parser.add_argument('--dry-run', action='store_true',
                        help='ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ (ì‹¤ì œ ì—…ë¡œë“œ ì•ˆ í•¨)')
    parser.add_argument('--force', action='store_true',
                        help='ê°•ì œ ì „ì²´ ì—…ë¡œë“œ (ìºì‹œ ë¬´ì‹œ)')

    args = parser.parse_args()

    upload_all(dry_run=args.dry_run, force=args.force)


if __name__ == '__main__':
    main()
